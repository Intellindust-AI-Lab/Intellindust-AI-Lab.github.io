<!DOCTYPE html>
<html lang="en">
<head>
  <title>DEIMv2</title>
  <meta charset="utf-8">
  <meta name="description" content="Real-Time Object Detection Meets DINOv3">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Open Graph / Social -->
  <meta property="og:title" content="DEIMv2"/>
  <meta property="og:description" content="Real-Time Object Detection Meets DINOv3"/>
  <meta property="og:type" content="website"/>
  <meta property="og:url" content="https://xishen0220.github.io/DEIMv2/"/>
  <meta property="og:image" content="resrc/DEIM.png"/>

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image"/>
  <meta name="twitter:title" content="DEIMv2"/>
  <meta name="twitter:description" content="Real-Time Object Detection Meets DINOv3"/>
  <meta name="twitter:image" content="resrc/DEIM.png"/>

  <!-- Fonts & CSS -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">

  <style>
    body { font-family: 'Inter', sans-serif; }
    h1, h2, h3, h4 { font-weight: 700; }

    .hero {
      text-align: center;
      padding: 4rem 1rem;
      background: linear-gradient(135deg, #0d6efd, #6610f2);
      color: white;
    }
    .hero h1 { font-size: 2.8rem; font-weight: 800; }
    .hero p { font-size: 1.1rem; }
    .hero a {
              color: #FFA07A !important;
              font-weight: 600;
            }
            .hero a:hover {
              color: #ffd700 !important; /* gold hover */
            }

    .btn-custom {
      margin: 0.3rem;
      border-radius: 2rem;
      padding: 0.6rem 1.4rem;
    }

    .section { padding: 3rem 1rem; }
    .img-hover:hover { transform: scale(1.03); transition: 0.3s ease; }
    pre { background: #f8f9fa; padding: 1rem; border-radius: 0.5rem; }
    footer { padding: 2rem; text-align: center; background: #f8f9fa; margin-top: 2rem; }

    /* ğŸ“± Mobile adjustments */
    @media (max-width: 768px) {
      .hero { padding: 2rem 1rem; }
      .hero h1 { font-size: 1.8rem; }
      .hero p { font-size: 1rem; }
      .section { padding: 2rem 1rem; }
      pre { font-size: 0.85rem; overflow-x: auto; }
    }

    /* è®©æ‰€æœ‰èµ„æºå¡ç‰‡é‡Œçš„å›¾ç‰‡ç»Ÿä¸€é«˜åº¦ã€åº•ç«¯å¯¹é½ */
  .res-card {
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: flex-end;
    height: 100%;
    padding: 15px;
    border-radius: 15px;
    background: #ffffff0d; /* åŠé€æ˜èƒŒæ™¯ï¼Œå¯é€‰ */
    transition: transform 0.2s ease, box-shadow 0.2s ease;
  }

  .res-card img {
    max-height: 200px; /* æ§åˆ¶ç»Ÿä¸€é«˜åº¦ */
    object-fit: contain; /* ä¿è¯æ¯”ä¾‹ */
    border: 2px solid #ddd; /* å›¾ç‰‡è¾¹æ¡† */
    border-radius: 12px;
    padding: 8px;
    background: #fff; /* ç™½è‰²èƒŒæ™¯è¡¬æ‰˜å›¾æ ‡ */
    transition: border-color 0.3s ease, transform 0.2s ease;
  }

  .res-card:hover {
    transform: translateY(-5px);
    box-shadow: 0 8px 20px rgba(0,0,0,0.2);
  }

  .res-card img:hover {
    border-color: #6a5acd; /* hover æ—¶è¾¹æ¡†é«˜äº®ï¼ˆç´«è‰²ç³»ï¼‰ */
    transform: scale(1.05);
  }

  .res-card h5 {
    margin-top: 12px;
    font-weight: 600;
    color: #6a5acd; /* æµ…è‰²æ–‡å­—ï¼Œä¸ç´«è‰²èƒŒæ™¯åè°ƒ */
}
  </style>
</head>
<body>

<!-- Hero Section -->
<div class="hero">
  <h1>Real-Time Object Detection Meets DINOv3</h1>
  <p class="lead">arXiv 2025</p>
  <p class="author-list">
    <a href="http://www.shihuahuang.cn/">Shihua Huang</a><sup>*1</sup> &emsp;
    Yongjie Hou<sup>*1,2</sup> &emsp;
    Longfei Liu<sup>*1</sup> &emsp;
    <a href="https://xuanlong-yu.github.io/"> Xuanlong Yu<sup>1</sup></a> &emsp;
    <a href="https://xishen0220.github.io/">Xi Shen<sup>â€ 1</sup></a>
  </p>
  <p>
    <sup>1</sup> <a href="https://github.com/Intellindust-AI-Lab">Intellindust AI Lab</a> &nbsp;|&nbsp;
    <sup>2</sup> Xiamen University <br>
    <sup>*</sup> Equal Contribution &nbsp; <sup>â€ </sup> Corresponding
  </p>
  <div class="d-flex justify-content-center flex-wrap">
    <a href="https://arxiv.org/abs/2412.04234" class="btn btn-light btn-custom"><i class="fas fa-book"></i> arXiv</a>
    <a href="https://github.com/Intellindust-AI-Lab/DEIMv2" class="btn btn-light btn-custom"><i class="fab fa-github"></i> Code</a>
    <a href="resrc/DEIM-Slides.pdf" class="btn btn-light btn-custom"><i class="fas fa-file-powerpoint"></i> Slides</a>
    <a href="resrc/CVPR2025_DEIM_poster.pdf" class="btn btn-light btn-custom"><i class="fas fa-image"></i> Poster</a>
  </div>
</div>


<!-- Abstract -->
<div class="container section text-center">
  <h3>Abstract</h3>
</div>
<div class="container section">
  <p style="line-height:1.6;">
    Benefiting from the simplicity and effectiveness of Dense O2O and MAL, DEIM has become the mainstream training framework for real-time DETRs, significantly outperforming the YOLO series. 
    In this work, we extend it with DINOv3 features, resulting in DEIMv2. DEIMv2 spans eight model sizes from X to Atto, covering GPU, edge, and mobile deployment. 
    For the X, L, M, and S variants, we adopt DINOv3-pretrained / distilled backbones and introduce a Spatial Tuning Adapter (STA), which efficiently converts DINOv3â€™s single-scale output into multi-scale features and complements strong semantics with fine-grained details to enhance detection. 
    For ultra-lightweight models (Nano, Pico, Femto, and Atto), we employ HGNetv2 with depth and width pruning to meet strict resource budgets. 
    Together with a simplified decoder and an upgraded Dense O2O, this unified design enables DEIMv2 to achieve a superior performanceâ€“cost trade-off across diverse scenarios, establishing new state-of-the-art results.
    Notably, our largest model, DEIMv2-X, achieves 57.8 AP with only 50.3M parameters, surpassing prior X-scale models that require over 60M parameters for just 56.5 AP. On the compact side, DEIMv2-S is the first sub-10M model (9.71M) to exceed the 50 AP milestone on COCO, reaching 50.9 AP. Even the ultra-lightweight DEIMv2-Pico, with just 1.5M parameters, delivers 38.5 APâ€”matching YOLOv10-Nano (2.3M) with $\sim$50\% fewer parameters. Code and pretrained weights are available at: <a href="https://github.com/Intellindust-AI-Lab/DEIMv2">https://github.com/Intellindust-AI-Lab/DEIMv2</a>
  </p>
</div>

<!-- Method -->
<div class="container section text-center">
  <h3>Method</h3>
  <img src="resrc/STA.png" alt="DEIMv2 STA method diagram" class="img-fluid img-hover">
</div>

<!-- Results -->
<div class="container section text-center">
  <h3>Results</h3>
  <div class="row text-center g-4">
    <div class="col-md-6 col-12">
      <h5>Perf. v.s. Params.</h5>
      <img src="resrc/teaser_a.png" alt="Convergence" class="img-fluid img-hover">
    </div>
    <div class="col-md-6 col-12">
      <h5>Perf. v.s. FLOPs.</h5>
      <img src="resrc/teaser_b.png" alt="Performance" class="img-fluid img-hover">
    </div>
  </div>
</div>

<!-- Resources -->
<div class="container section text-center">
  <h3>Resources</h3>
  <br>
  <div class="row g-4">
    <div class="col-md-4 col-12">
      <div class="res-card">
        <a href="https://arxiv.org/abs/2412.04234">
          <img src="resrc/arxiv.png" alt="arxiv" class="img-fluid img-hover">
        </a>
        <h5>arXiv</h5>
      </div>
    </div>

    <div class="col-md-4 col-12">
      <div class="res-card">
        <a href="https://github.com/Intellindust-AI-Lab/DEIMv2">
          <img src="resrc/github.png" alt="github" class="img-fluid img-hover">
        </a>
        <h5>Code</h5>
      </div>
    </div>

    <div class="col-md-4 col-12">
      <div class="res-card">
        <a href="resrc/DEIM-Slides.pdf">
          <img src="resrc/slides.png" alt="slides" class="img-fluid img-hover">
        </a>
        <h5>Slides</h5>
      </div>
    </div>
  </div>
</div>

<!-- BibTeX -->
<div class="container section">
  <h3>BibTeX</h3>
  <p>If you find this work useful, please cite:</p>
  <pre>
@article{huang2025deimv2,
  title={Real-Time Object Detection Meets DINOv3},
  author={Huang, Shihua and Hou, Yongjie and Liu, Longfei and Wang, Zizhen and Yu, Xuanlong and Shen, Xi},
  journal={arXiv},
  year={2025}
}
  </pre>
</div>

<!-- Footer -->
<footer>
  <p>&#169; 2025 DEIMv2 Authors.</p>
</footer>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootst
